<!DOCTYPE html>
<html>
<head>
    <link rel="shortcut icon" href="{{ url_for('static', filename='favicon.ico') }}">
    <title>DeepReader</title>
    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merienda One">
    <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Port Lligat Slab">
    <link rel="stylesheet" type="text/css" href="{{ url_for('static', filename='up.css') }}">
    <link rel="stylesheet" type="text/css" href="{{ url_for('static', filename='menu.css') }}">
    <link href="//getbootstrap.com/dist/css/bootstrap.min.css" rel="stylesheet">
 
    <script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min.js"></script>
    <!-- load D3.j from the web -->
    <script type="text/javascript" src="//d3js.org/d3.v3.min.js"></script>

    <script type="text/javascript" src="{{ url_for('static', filename='d3.layout.cloud.js') }}"></script>

    <!-- Latest compiled and minified CSS -->
  <link rel="stylesheet" href="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">

  <!-- jQuery library -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>

  <!-- Latest compiled JavaScript -->
  <script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>


    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-57004914-2', 'auto');
  ga('send', 'pageview');

</script>


    <!-- // <script type="text/javascript" src="{{ url_for('static', filename='require.js') }}"></script> -->
    <style>
      /* tell the SVG path to be a thin blue line without any area fill */
      path {
        stroke-width: 5;
        stroke-opacity: 0.8;
        fill: none;
      }
      
      .x.axis line ,x.axis path{
        fill: none;
        stroke: lightgrey;
        stroke-width: 2;
        stroke-opacity: 0.5;
      }

      .y.axis line, .y.axis path {
        fill: none;
        stroke: lightgrey;
        stroke-width: 2;
        stroke-opacity: 0.5;
      }

      div.tooltip {   
        position: absolute;           
        text-align: center;                            
        padding: 5px;             
        font: 12px Open Sans;        
        background: white;   
        border: 0px;      
        border-radius: 2px;           
        pointer-events: none;   
        box-shadow: 0 8px 10px 1px rgba(0, 0, 0, .14), 0 3px 14px 2px rgba(0, 0, 0, .12), 0 5px 5px -3px rgba(0, 0, 0, .2);  
      }

      .row {
        padding: 20px;
      }
      .box-shadow--2dp {
          box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12)
      }
      .box-shadow--3dp {
          box-shadow: 0 3px 4px 0 rgba(0, 0, 0, .14), 0 3px 3px -2px rgba(0, 0, 0, .2), 0 1px 8px 0 rgba(0, 0, 0, .12)
      }
      .box-shadow--4dp {
          box-shadow: 0 4px 5px 0 rgba(0, 0, 0, .14), 0 1px 10px 0 rgba(0, 0, 0, .12), 0 2px 4px -1px rgba(0, 0, 0, .2)
      }
      .box-shadow--6dp {
          box-shadow: 0 6px 10px 0 rgba(0, 0, 0, .14), 0 1px 18px 0 rgba(0, 0, 0, .12), 0 3px 5px -1px rgba(0, 0, 0, .2)
      }
      .box-shadow--8dp {
          box-shadow: 0 8px 10px 1px rgba(0, 0, 0, .14), 0 3px 14px 2px rgba(0, 0, 0, .12), 0 5px 5px -3px rgba(0, 0, 0, .2)
      }
      .box-shadow--16dp {
          box-shadow: 0 16px 24px 2px rgba(0, 0, 0, .14), 0 6px 30px 5px rgba(0, 0, 0, .12), 0 8px 10px -5px rgba(0, 0, 0, .2)
      }
      .top-buffer { margin-top:20px; }



HTML, BODY {
  height: 100%;
}

svg {
  background: white;
  background-size: .12em 100%;
  font: 12em/1 Open Sans;
}

.text--line {
  font-size: .5em;
}
/*
svg {
  position: absolute;
  width: 100%;
  height: 100%;
}*/

.text-copy {
  fill: none;
  stroke: white;
  stroke-dasharray: 7% 28%;
  stroke-width: 3px;
  -webkit-animation: stroke-offset 5s infinite linear;
          animation: stroke-offset 5s infinite linear;
}
.text-copy:nth-child(1) {
  stroke: #1abc9c;
  stroke-dashoffset: 7%;
}
.text-copy:nth-child(2) {
  stroke: #e74c3c;
  stroke-dashoffset: 14%;
}
.text-copy:nth-child(3) {
  stroke: #f1c40f;
  stroke-dashoffset: 21%;
}
.text-copy:nth-child(4) {
  stroke: #3498db;
  stroke-dashoffset: 28%;
}
.text-copy:nth-child(5) {
  stroke: #e67e22;
  stroke-dashoffset: 35%;
}

@-webkit-keyframes stroke-offset {
  50% {
    stroke-dashoffset: 70%;
    stroke-dasharray: 0 87.5%;
  }
}

@keyframes stroke-offset {
  50% {
    stroke-dashoffset: 35%;
    stroke-dasharray: 0 87.5%;
  }
}



}



}


body {
      position: relative; 
  }
  .sec1 { background-color: #e74c3c;}
  .sec2 { background-color: #3498db;}
  .sec3 { background-color: #9b59b6;}
  .sec4 { background-color: #2ecc71 ;}
  .sec5 {  background-color: #34495e;}

  .bloc{padding:50px; color:white;}

  a{color: lightgrey;}

  .circular {
  width: 200px;
  height: 200px;
  border-radius: 100px;
  -webkit-border-radius: 100px;
  -moz-border-radius: 100px;
  
  }
  .valentin{
    background: url({{ url_for('static', filename='valentin.jpg') }}) no-repeat;
  }

  .yannis
  {
    background: url({{ url_for('static', filename='yannis.jpg') }}) no-repeat;
  }

.circular img {
  opacity: 0;
  filter: alpha(opacity=0);
  }




    </style>
</head>
<body data-spy="scroll" data-target=".navbar" data-offset="50">


    <nav class="navbar navbar-default">
    <div class="container-fluid">
      <div class="navbar-header">
        <img class="img-responsive" alt="Logo" src="{{ url_for('static', filename='logo.png') }}">
      </div>
      <div>
        <ul class="nav navbar-nav">
          <li class="active"><a href="/presentation">Presentation</a></li>
          <li><a href="/corpusnet">Network</a></li> 
	  <li><a href="/d3">Text Analysis</a></li>
        </ul>
      </div>
    </div>
  </nav>



<svg viewBox="0 0 800 400">
  <symbol id="s-text">
    <text text-anchor="middle"
          x="50%"
          y="35%"
          class="text--line"
          >
      Deep
    </text>
    <text text-anchor="middle"
          x="50%"
          y="68%"
          class="text--line2"
          >
      Reader
    </text>
    
  </symbol>
  
  <g class="g-ants">
    <use xlink:href="#s-text"
      class="text-copy"></use>     
    <use xlink:href="#s-text"
      class="text-copy"></use>     
    <use xlink:href="#s-text"
      class="text-copy"></use>     
    <use xlink:href="#s-text"
      class="text-copy"></use>     
    <use xlink:href="#s-text"
      class="text-copy"></use>     
  </g>
  
  
</svg>

<div  class="bloc sec1 container-fluid">
  <h1>Work in progress</h1>
  <p>This project is currently under development</p>
</div>
<div  class="bloc sec2 container-fluid">
  <h1>What is it?</h1>
  <p>This is project developped in the context of the Msc Digital Media Engineering at DTU in partnership with <a href="http://www.easytranslate.com/">EasyTranslate</a></p>
  <p>The goal is to provide tools to understand a text without reading it and to explore a corpus and the relations between texts</p>
  <p>EasyTranslate is a translation company. The company is supported with specialized translators. Today, when a client uploads a text, a manager reads it quickly and routes it to the right translators. We propose tools to bypass the reading-through process by analysing the text with natural language processing tools. Moreover, we propose also an overview of the already translated documents: the corpus network. This corpus gives a representation of the texts and provides a notion of distance between texts. Thus, thanks to these semantic distances between texts, we can find the right translator automatically: the translator who has translated the closest text.</p>
  <p>We provide an analysis on two levels</p>
    <li>Relations with other texts using the cosine similarity</li>
    <li>Topic distribution, complexity and most important words within a text</li>
</div>
<div class="bloc sec4 container-fluid">
  <h1>How to use it?</h1>

  <div class="container-fluid">
      <div class="row top-buffer ">


      <div class="col-md-4">
            <img class="box-shadow--8dp" src="{{ url_for('static', filename='preview.gif') }}" alt="how it works" style="width: 100%;"><br>
        </div>


        <div class="col-md-8" >
          <h2>Corpus vizualisation</h2>
          <p>The page <a href="/corpusnet">Network</a> shows a network composed of nodes. Nodes represent texts, and links represent the similarity between texts. The more a link is thick the more the texts are close. The graph provides a nice way to vizualise a corpus. </p>
          <p><strong>Play with the network</strong>, try to understand what the texts are about, explore the relationships between texts.</p>


          <p>You can see different types of nodes:
          <li>the lightest and largest represent topics built with the LDA</li>
          <li>the smallest and darker nodes represent texts</li></p>
        </div>

        <div class="col-md-8" >
          <h2>Single text analysis</h2>

          <p>The page <a href="/d3">Text Analysis</a> shows the analysis of a single text. this page analysis a random text in the corpus. However, you can access to the analysis of any text in the corpus from the network (button in the left panel).</p>
          <p>This page shows the distribution of topics along the text, the complexity based on the <a href="https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests">Flesch reading ease</a>, and the most important words for each topic presented with a wordcloud and a graph.</p>
          <p>Keep in mind that the main goal is to provide a tool which help a manager to understand a text and have an idea of the difficulty and the most difficult words in the text. However, the analysis page provides also tools which help us to understand the content of a text: the force directed graph for example provides a nice overview of the text because it gives directly examples of significant (and complex) words.</p>
        </div>
      </div>

  </div>
  <div class="container-fluid">


      <div class="row top-buffer ">


      <div id="topics" class="col-md-4 text-center">
            <img class="box-shadow--8dp" src="{{ url_for('static', filename='communities2.gif') }}" alt="how it works" style="width: 100%;"><br>
        </div>


        <div class="col-md-8" >
          <h2>Communities</h2>
          <p>We use a python implementation of the Louvain-algroithm in order make a partition of communities. Communities are groups of nodes where documents are highly similar.</p>
          <p>The modularity, which indicates the quality of the partition is around 0.62 which indicates the partition is quite good (modularity varies from -0.5 to 1, a modularity of 1 indicates the groups are well delimited)</p>
          <p>We also colored seperated components with more than 2 documents. Thus, it gives a nice visualisation of the groups within the corpus. The analysis of the communities shows that groups defined thanks to the Louvain-algorithm make sense. For example, the purple community corresponds to the texts about philosophy.</p>
        </div>



    </div>

  
  </div>
</div>

<div class="bloc sec1 container-fluid text-center" style="background-color: #555555">

  <a href="/corpusnet"><button type="button" class="btn btn-warning box-shadow--8dp btn-lg">Try this amazing app</button></a>

</div>



<div class="bloc sec3 container-fluid">
  <h1>Where the data come from?</h1>
  <p>Texts come from different sources.
  <li> The <a href="http://www.anc.org/data/masc/">MASC corpus</a> which provides a great variety of texts. However, some texts and categories have been removed in order to obtain a better repartition of texts.</li>
  <li>The <a href="https://www.gutenberg.org/">Gutemberg project</a> which provides a huge quantity of texts from different topics. Texts have been chosen according to their topics.
  <li>Some random texts like the iPhone user guide or the Apache License.</li>
</div>



<div class="bloc sec5 container-fluid">
  <h1>How topics are made?</h1>

  <p>Topics have been made thanks to the <a href="https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation">LDA</a> (Latent Dirichlet Allocation). We used <a href="https://radimrehurek.com/gensim/n">Gensim</a>, an open source libray in python for natural language processing on the 5,025,150 articles from the English Wikipedia (one day of computation). The LDA is a model which enable from a corpus of texts to extract a given ammount of topics. Topics are groups of words with a semantic realtion. Topics are composed of a list of weighted words.</p>

  <p>Topics are made accoridng to a mathematical model and are based on statisitcs. Thus, a word taken alone within a topic often doesn't make sens: topics give a probability for each word to belong to a topics (and can be present in several topics) because words are used in different contexts.</p>

  <p>In order to provide an overview of the texts without seeing the whole content of a topic, we named manually the most used topics. Therefore, some topic names are just an overall description of the topics. For example the topic "everyday vocabulary" corresponds to a lot of adjectives or vocabulary related to dialogues. Thus, this vocabulary can be used in a lot of differents contexts: text about marketing for example are characterized by an high proportion of this topic because this kind of text use a lot of positive adjectives.We can make the same observation for movie scripts or fictions which are also characterized by this topic whereas it can be a movie or fiction about war or fantasy.</p>

</div>  


<div class="bloc sec5 container-fluid">
  <h1>What are the relations bewteen texts?</h1>

 <div class="container-fluid">
      <div class="row top-buffer ">


      <div id="topics" class="col-md-4 ">
            <img  class= "box-shadow--8dp" src="{{ url_for('static', filename='cosine.jpg') }}" alt="how it works" style="width: 100%;"><br>
        </div>

        <div class="col-md-8" >
          <h2>Cosine similarity</h2>
          <p>The distance between texts is based on the cosine similarity in the topic space. Each topic represents a dimension (on the example, the dimensions are the topics "economy", "mathematis" and "food"). The cosine similarity is basically the cosine of the angle between two vectors in the topic space. The diagram on the left shows how it works with three topics: the cosine similarity corresponds to the cosine of the angle Θ between the two vector. The same principle is applicable with 100 dimensions.</p>

          <p>In order to obtain a graph that makes sense, we applies a threshold to the similarities: only the similarities higher than 85% are kept.</p>

        </div>

      
      </div>
    </div>




</div>


<div class="bloc sec5 container-fluid">
  <h1>How are the texts analysed?</h1>

  <h2>Topics distribution</h2>

  <p>Thanks to the LDA, we extract the topics from small chuncks in the text. It gives a probability for each part to belong to a specific topic. Texts need to be tokenized for the LDA.</p>
  <p>The LDA topics are mathematically made and are based on assumptions which aren't always verified on the wikipedia corpus and in the texts we analyze. Moreover, the LDA is a model, a simplification of the world. Thus, the LDA cannot handle every nuances of the language. This is why some results need an interpretation. However, the results are quite good and give a nice overview of a text without reading it.</p>

  <h2>Complexity</h2>

  <p>We introduced the complexity because of our motivations for this project. Indeed, the goal is to provide a tool for managers in a translation company to allocate a text to the right translator without reading the text. Thus, evaluate the complexity of the text can help the manager to choose the right translator. Moreover, the complexity will also be used for dynamic pricing: a complex text requires more ressources to be translated. Then, the translation cost should be higher than for a less complex text.</p>

  <p>We use the <a href="https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests">Flesch reading ease</a> forumla to give an estimation of the complexity along the text. This formula is based on the length of the words, the number of syllabus and the length of the words. Basically, a text is hard to read if the sentences and the words are long. This forumla gives an estimation of the complexity on a scale from 0 to 100 (we inversed the original scale). Scores can be interpreted with the following table:<p>
  <li>0-10: easily understood by an average 11-year-old student</li>
  <li>30-40: easily understood by 13- to 15-year-old students</li>
  <li>70-100: best understood by university graduates</li>

  <h2>Meaningful words</h2>

  <p>In order to help a manager in its choices, we need to provide the most important words in a text to help him to spot if the text is about a special topic (like a text with difficult law or medecine vocabulary).</p>

  <p>Usual scoring-functions like the TF-IDF was not working very well and it was very time-consuming. We developped our own scoring-function to sort words with regard to their difficulty and importance in the text. </p>

  <p>This function is quite simple and is basically the length of the words divided by the frequency of the word in english. It can seem to be a strange and very basic but sometimes, less is more, we obtain very good results compared to the traditional TF-IDF.</p>

  <p>The frequencies of the words are defined on to the Reuter corpus from NLTK. The choice of the length of the words as a characteristic parameter is motivated by the fact than, in English, the more a word is long, the more the word carry meaning and the more the word is likely to be difficult. we use the frequencies of the words in english to filter the common words.</p>
</div>  

<div class="bloc sec4 container-fluid">
  <h1>Which technologies are used?</h1>
  <h2>Back-End</h2>
  <p>The back-end groups all the work behind the scene. Due to technical limitations, all the analysis have been made computed one time and the results have been stored in a data base. Indeed, free hosts like heroku doesn't provide enough computation power to load and run the LDA based on the whole wikipedia.</p>
  <p>However, we also built a prototype which analysises texts on-the-go: the user upload a text a get the results instantly.<p>
  <p>All the analyses are made with python. Here is a list of all the libraries used in the project<p>
  <li><a href="https://radimrehurek.com/gensim/n">Gensim</a>: a powerful language processing python library with an implementation of the LDA model</li>
  <li><a href="http://www.nltk.org/">NLTK</a>: our favorite language processing platform for python. It contains over 50 corpora and lexical ressources and provides also tools for classification, tokenization, stemming, tagging, parsing, and semantic reasoning. We use it for text cleaning, tokenizing and word frequency count but also to get useful data like the Reuters corpus.</li>
  <li><a href="https://networkx.github.io/">NetworkX</a>: an awesome python library for network analysis.</li>
  <li><a href="http://perso.crans.org/aynaud/communities/">A python Louvain-algorithm implementation</a>: the Louvain-algorithm is an algorithm for community detection (detection of "groups" of nodes). It finds an optimal partition of the network with reagrd to the modularity.</li>
  <li><a href="http://flask.pocoo.org/">Flask</a>: a microframework for Python based on Werkzeug and Jinja 2. It enables us to build this application easily and manage the different webpages</li>
  <li>Hosts:
  <ul>
    <li><a href="https://www.heroku.com/">Heroku</a>: the platform where is hosted this application</li>
    <li><a href="https://mongolab.com/">Mongolab</a>: the platform which hosts our database</li>
  </ul>
  </li>


  <h2>Front-End</h2>

  <p>The front-end represents all the work you see, here, on this app. Its includes the webpages and the graphs</p>

  <li><a href="http://getbootstrap.com/">Bootstrap</a>: a popular framework for developing responsive, mobile first projects on the web.</li>
  <li><a href="http://d3js.org/">d3</a>: an amazing JavaScript library for data vizualisation: all graphs have been made thanks to this library</li>


  
</div>  


<div class="bloc sec5 container-fluid">
  <h1>Corpus Analysis</h1>
  <p>The network is composed from 222 nodes including the 100 topics.</p>
  <p>
  <!-- <p> things about network and corpus analysis, technical stuff............WIP</p> -->
</div>  





<div class="bloc sec1 container-fluid">
  <h1>Limitations</h1>

    <p>Topics are modelised on the whole english wikipedia and only 100 categories are represented. Thus, the possibilities are limited, we can differentiate a user guide and a movie script but we cannot differentiate a horror movie script and a romantic movie script because the language used for both documents is very close (dialogues). 


</div>  


<div class="bloc  container-fluid"style = "color: #cccccc;">
  <h1>About us</h1>

  <div class="container-fluid text-center" >
      
      <div class="row top-buffer text-center">
        <div  class="col-md-2 box-shadow--4dp text-center" style="text-align: center; min-height: 600px;  width: 300px; margin-right: 50px; margin-left: 50px;">

        <div style="text-align: center; width: 100%; padding: 30px;">
          <div class="circular valentin text-center"><img src="{{ url_for('static', filename='valentin.jpg') }}" alt="" /></div>
        </div>
            <h2>Valentin Liévin</h2>
            <p>Student in Msc. Digital Media Engineering at DTU (Denmark)</p>
        </div>

        <div class="col-md-2 box-shadow--4dp text-center" style="text-align: center;min-height: 600px;  width: 300px;margin-left: 50px; margin-right: 50px;">

        <div style="text-align: center; width: 100%; padding: 30px;">
          <div class="circular yannis text-center"><img src="{{ url_for('static', filename='yannis.jpg') }}" alt="" /></div>
        </div>


          <h2>Yannis Flet-Berliac</h2>
          <p>Student in Msc. Digital Media Engineering at DTU (Denmark)</p>
        </div>
      </div>
    </div>


</div>  


    
</body>
</html>

<!--
d3.json("/data", function(error, data) {

});





        canvas.selectAll("rect")
        .data(loaded_data)
        .enter()
          .append("rect")
          .attr("width", function(d) {return wScale(d.y)})
          .attr("y", function(d,i){return i * 50})
          .attr("height", 40)
          .attr("fill", '#1abc9c');






          d3.json("/data", function(error,loaded_data) {


        var width = 600;
        var height = 300;

        var wScale = d3.scale.linear()
        .domain([0, 100]).range( [0, width] );

        var canvas = d3.select("body").append("svg")
        .attr("width", height)
        .attr("height", width);

        var group = canvas.append("g")
        .attr( "transform", "translate(0, 0)");


        var line = d3.svg.line()
        .x(function(d) {return d.x; })
        .y(function(d) {return d.y;});

        group.selectAll("path")
        .data(loaded_data)
        .enter()
        .append("path")
        .attr("d", line)
        .attr("fill", "none")
        .attr("stroke", 'black')
        .attr('stroke-width', 10)






      });


      -->
