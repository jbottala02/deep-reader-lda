{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version 2.7.10 |Anaconda 2.3.0 (64-bit)| (default, Nov  7 2015, 13:18:40) [MSC v.1500 64 bit (AMD64)]\n",
      "Pymongo version 3.1.1\n",
      "\n",
      "Connecting ...\n",
      "\n",
      "Getting database ...\n",
      "\n",
      "Authenticating ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a database already created on mongolab \n",
    "server = 'ds059694.mongolab.com'\n",
    "port = 59694\n",
    "db_name = 'deepreader'\n",
    "username = 'deepreaderuser'\n",
    "password = '1ecolequimonte45'\n",
    "\n",
    "from pymongo import MongoClient as Connection\n",
    "\n",
    "# from pymongo import Connection\n",
    "\n",
    "# what versions are we using\n",
    "import sys\n",
    "print 'Python version', sys.version\n",
    "\n",
    "import pymongo\n",
    "print 'Pymongo version', pymongo.version\n",
    "##\n",
    "\n",
    "# connect to server\n",
    "print '\\nConnecting ...'\n",
    "conn = Connection(server, port)\n",
    "\n",
    "# Get the database\n",
    "print '\\nGetting database ...'\n",
    "db = conn[db_name]\n",
    "\n",
    "# Have to authenticate to get access\n",
    "print '\\nAuthenticating ...'\n",
    "db.authenticate(username, password)\n",
    "# from pymongo import MongoClient\n",
    "# client = MongoClient()\n",
    "# db = client.izidb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------> english word frequencies loaded\n",
      "--------------------> english word frequencies loaded\n"
     ]
    }
   ],
   "source": [
    "from scripts import izi\n",
    "reload(izi)\n",
    "\n",
    "n_topics = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get files list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "1412 Standard English Review-en-ru-T.mxliff\n"
     ]
    }
   ],
   "source": [
    "root = u\"../izi_data/\"\n",
    "filelist = izi.getFileList(root)\n",
    "print len(filelist)\n",
    "example =  filelist[0]\n",
    "print example[len(root):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def safe_str(value):\n",
    "    if type(value) == str:\n",
    "    # Ignore errors even if the string is not proper UTF-8 or has\n",
    "    # broken marker bytes.\n",
    "    # Python built-in function unicode() can do this.\n",
    "        value = unicode(value, \"utf-8\", errors=\"ignore\")\n",
    "    else:\n",
    "    # Assume the value object has proper __unicode__() method\n",
    "        value = unicode(value)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "def loadTranslator(path):   \n",
    "    if path[-4:] == 'liff':\n",
    "        soup = BeautifulSoup( open(path), 'lxml')\n",
    "        for string in soup.find_all(\"file\"):\n",
    "            try:\n",
    "                return string['m:task-id']\n",
    "            except:\n",
    "                return -1\n",
    "            \n",
    "            \n",
    "def insertDoc(path, root = root, prefix = ''):\n",
    "    document = dict()\n",
    "#     document['title'] = prefix + '___' + path[len(root):].replace( ' ', '_')\n",
    "    document['title'] = path[len(root):].replace( ' ', '_')\n",
    "    document['type'] = prefix\n",
    "    document['translator'] = loadTranslator(path)\n",
    "    current_translator = db.translators.find_one({'name': document['translator']})\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        full_text = izi.loadText(path)\n",
    "    #     full_text = unicode(full_text, errors='ignore')\n",
    "        full_text = safe_str(full_text)\n",
    "\n",
    "        if len(full_text) > 500:\n",
    "            if not current_translator:\n",
    "                translator = dict()\n",
    "                translator['name'] = document['translator']\n",
    "                translator['document'] = []\n",
    "                id_current_translator = db.translators.save(translator)\n",
    "                current_translator = db.translators.find_one({'name': document['translator']})\n",
    "\n",
    "            # text and tokens\n",
    "            tokens = izi.tokenize( full_text)\n",
    "            document['full_text'] = full_text\n",
    "            document['tokens'] = tokens\n",
    "            # topics\n",
    "            topics =  izi.topicsFromTokens(izi.tokenize(full_text))\n",
    "            semantic_vec = [0.] * n_topics\n",
    "            for i in topics:\n",
    "                semantic_vec[i[0]] = i[1]\n",
    "            document['semantic_vec'] = semantic_vec\n",
    "            # complexity\n",
    "            document['complexity'] = izi.complexityAlongtheText(full_text)\n",
    "            # topic distribution\n",
    "            document['full_topics'] = izi.getTopicDistributionData( document['full_text'], document['semantic_vec'])\n",
    "            # significants words\n",
    "            document['significantWords'] = izi.getMostSignificantWordsData(document['tokens'] , document['semantic_vec'])\n",
    "            # significant words graph\n",
    "            document['topicsGraph'] = izi.SignificantWordsGraph(document['tokens'] , document['semantic_vec'] )\n",
    "\n",
    "            ##\n",
    "            # savec doc\n",
    "            current_id = db.documents.save(document)\n",
    "            current_translator['document'].append(current_id)\n",
    "            db.translators.update({'name': document['translator']}, {'name': document['translator'],\\\n",
    "                                                                     'document': current_translator['document']})\n",
    "\n",
    "\n",
    "            ###################\n",
    "            # create links\n",
    "            cursor = db.documents.find()\n",
    "            for doc in cursor:\n",
    "                y = doc['semantic_vec']\n",
    "                y_id = doc[\"_id\"]\n",
    "                if y_id != current_id:\n",
    "                    s = izi.getSimilarity( semantic_vec, y)\n",
    "                    db.similarities.insert({'source': current_id , 'target': y_id, 'value': s})\n",
    "    except:\n",
    "        print \"############################################################\"\n",
    "        print \"#### ERROR: \" + document['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class idGenerator:\n",
    "\tdef __init__(self):\n",
    "\t\tself.id = 0\n",
    "\tdef get(self):\n",
    "\t\tself.id += 1\n",
    "\t\treturn self.id - 1\n",
    "    \n",
    "def getLastAdded():\n",
    "\tcurrent_id = None\n",
    "\tfor d in db.documents.find().sort(\"_id\", -1).limit(1) :\n",
    "\t\tcurrent_id = d\n",
    "\treturn db.documents.find_one( { \"_id\" : current_id[\"_id\"] })\n",
    "\n",
    "\n",
    "def getGraph():\n",
    "    SIMILARITY_CUTOFF = 0.85\n",
    "\n",
    "    lasDoc = getLastAdded()\n",
    "    semantic_vectors = dict()\n",
    "    list_ids = db.documents.find().distinct(\"_id\")\n",
    "    current_id = lasDoc[\"_id\"]\n",
    "\n",
    "    id2db = dict()\n",
    "    gen = idGenerator()\n",
    "\n",
    "    nodes = []\n",
    "    for ii in list_ids:\n",
    "        doc = db.documents.find_one( {'_id' : ii} )\n",
    "        node = dict()\n",
    "        tmp_id = doc[\"_id\"]\n",
    "        i = gen.get()\n",
    "        id2db[str(tmp_id)] = i\n",
    "        node[\"id\"] = i\n",
    "        node['color'] = \"#555555\"\n",
    "        node['size'] = 5\n",
    "        node['id_db'] = str(tmp_id)\n",
    "        node['name'] = doc['title']\n",
    "        nodes.append(node)\n",
    "\n",
    "    cursor = db.similarities.find()\n",
    "    edges = []\n",
    "    for e in cursor:\n",
    "        if e['value'] > SIMILARITY_CUTOFF:\n",
    "            a = e['source']\n",
    "            b = e['target']\n",
    "            edge = {'source': id2db[str(a)] , 'target': id2db[str(b)], 'value': e['value']}\n",
    "            edges.append(edge)\n",
    "\n",
    "\n",
    "    graph = dict()\n",
    "    graph['nodes'] = nodes\n",
    "    graph['links'] = edges\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root2 = u\"../brown/\"\n",
    "import nltk\n",
    "brown_ids = nltk.corpus.brown.fileids()\n",
    "for i in brown_ids:\n",
    "    f = open( root2 + i + \".txt\", \"w\")\n",
    "    f.write(nltk.corpus.brown.raw(i) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in izi.getFileList(root2):\n",
    "    insertDoc(f, root = root2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cursor = db.documents.find_one({ \"_id\": id})\n",
    "# for document in cursor:\n",
    "#     print document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "root_scripts = u\"../scripts_movies/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('raw_script_urls.txt', 'r')\n",
    "for l in f.readlines():\n",
    "    ll =  [ u.rstrip() for u in l.split(' +++$+++ ') ]\n",
    "    title = ll[1]\n",
    "    title = title.replace(\" \", \"_\")\n",
    "    link = ll[2]\n",
    "    try:\n",
    "        p = urllib.urlopen(link).read()\n",
    "        if len(p) > 1000:\n",
    "            print link + ' ' + title\n",
    "            path = root_scripts + title + \".txt\"\n",
    "            file = open( path, \"w\")\n",
    "            \n",
    "            file.write( p )\n",
    "            insertDoc(path, root = root_scripts)\n",
    "        else:\n",
    "            print 'TOO SHORT: ' + link + ' ' + title\n",
    "    except:\n",
    "        print \"ERROR: \" + title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print izi.getFileList(root_scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fails = []\n",
    "print len(izi.getFileList(root_scripts))\n",
    "i = 0\n",
    "for f in izi.getFileList(root_scripts):\n",
    "    try:\n",
    "        insertDoc(f, root = root_scripts)\n",
    "        print i,\n",
    "    except:\n",
    "        fails.append(f)\n",
    "        print \"#\",\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# masc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  |   ../masc/fiction/Alices Adventures in Wonderland.txt\n",
      "Error(ASL): Sentence Count is Zero, Cannot Divide"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:31: DeprecationWarning: save is deprecated. Use insert_one or replace_one instead\n",
      "C:\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:55: DeprecationWarning: save is deprecated. Use insert_one or replace_one instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cannot compute complexity in 'complexityAlongtheText' \n",
      "1  |   ../masc/fiction/A_Wasted_Day.txt\n",
      "Error(ASL): Sentence Count is Zero, Cannot Divide"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:57: DeprecationWarning: update is deprecated. Use replace_one, update_one or update_many instead.\n",
      "C:\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:68: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cannot compute complexity in 'complexityAlongtheText' \n",
      "2  |   ../masc/fiction/captured_moments.txt\n",
      "3  |   ../masc/fiction/hotel-california.txt\n",
      "4  |   ../masc/fiction/lw1.txt\n",
      "4  |   ../masc/fiction/Nathans_Bylichka.txt\n",
      "4  |   ../masc/fiction/The Adventures of Sherlock Holmes.txt\n",
      "4  |   ../masc/fiction/The Iliad of Homer.txt\n",
      "4  |   ../masc/fiction/The_Black_Willow.txt\n",
      "4  |   ../masc/law/A Book About Lawyers.txt\n",
      "4  |   ../masc/law/An Account of the Proceedings on the Trial.txt\n",
      "4  |   ../masc/law/Briefless Ballads and Legal Lyrics.txt\n",
      "4  |   ../masc/law/Business Hints for Men and Women.txt\n",
      "4  |   ../masc/law/Childrens Internet Protection Act.txt\n",
      "4  |   ../masc/law/Commentaries on the Laws of Englan.txt\n",
      "4  |   ../masc/law/John Marshall and the Constitution.txt\n",
      "4  |   ../masc/law/Law and Laughter.txt\n",
      "4  |   ../masc/law/Our Legal Heritag.txt\n",
      "4  |   ../masc/law/Popular Law-making.txt\n",
      "4  |   ../masc/law/Report of the Decision of the Supreme Court.txt\n",
      "4  |   ../masc/law/The Acts Of The General Assemblies of the.txt\n",
      "4  |   ../masc/law/The Acts of Uniformity.txt\n",
      "4  |   ../masc/law/The Constitution of the United States.txt\n",
      "4  |   ../masc/law/The Declaration of Independenc.txt\n",
      "4  |   ../masc/law/The Divine Right of Church Government.txt\n",
      "4  |   ../masc/law/The English Constitution.txt\n",
      "4  |   ../masc/law/The Federalist Papers.txt\n",
      "4  |   ../masc/law/The Laws Of War.txt\n",
      "4  |   ../masc/law/The Magna Carta.txt\n",
      "4  |   ../masc/law/The United StatesConstitution.txt\n",
      "4  |   ../masc/law/the_common_law.txt\n",
      "4  |   ../masc/licenses/gpl.txt\n",
      "4  |   ../masc/licenses/iphone_user_guide.txt\n",
      "4  |   ../masc/licenses/LICENSE_apache.txt\n",
      "4  |   ../masc/licenses/mozilla_license.txt\n",
      "4  |   ../masc/medecine/A Manual of the Operations of Surgery.txt\n",
      "4  |   ../masc/medecine/Appendicitis.txt\n",
      "4  |   ../masc/medecine/Bronchoscopy and Esophagoscopy.txt\n",
      "4  |   ../masc/medecine/Making Good On Private Dutyhumanistic-nursing.txt\n",
      "4  |   ../masc/medecine/Manual of Surgery Volume First.txt\n",
      "4  |   ../masc/medecine/Surgical Anatomy.txt\n",
      "4  |   ../masc/medecine/The Kama Sutra of Vatsyayana.txt\n",
      "4  |   ../masc/movie-script/aliens.txt\n",
      "4  |   ../masc/movie-script/american_psycho.txt\n",
      "4  |   ../masc/movie-script/hannibal.txt\n",
      "4  |   ../masc/movie-script/independence_day.txt\n",
      "4  |   ../masc/movie-script/jackie_brown.txt\n",
      "4  |   ../masc/movie-script/jaws.txt\n",
      "4  |   ../masc/movie-script/JurassicParkIV-INT.txt\n",
      "4  |   ../masc/movie-script/JurassicParkIV-Scene_1.txt\n",
      "4  |   ../masc/movie-script/JurassicParkIV-Scene_3.txt\n",
      "4  |   ../masc/movie-script/JurassicParkIV-Scene_4.txt\n",
      "4  |   ../masc/movie-script/JurassicParkIV-Scene_5.txt\n",
      "4  |   ../masc/movie-script/pirates.txt\n",
      "4  |   ../masc/movie-script/psycho.txt\n",
      "4  |   ../masc/movie-script/titanic.txt\n",
      "4  |   ../masc/newspaper_newswire/20020731-nyt.txt\n",
      "4  |   ../masc/newspaper_newswire/NYTnewswire1.txt\n",
      "4  |   ../masc/newspaper_newswire/NYTnewswire2.txt\n",
      "4  |   ../masc/newspaper_newswire/NYTnewswire3.txt\n",
      "4  |   ../masc/newspaper_newswire/NYTnewswire4.txt\n",
      "4  |   ../masc/newspaper_newswire/NYTnewswire5.txt\n",
      "4  |   ../masc/newspaper_newswire/NYTnewswire6.txt\n",
      "4  |   ../masc/newspaper_newswire/NYTnewswire7.txt\n",
      "4  |   ../masc/newspaper_newswire/NYTnewswire8.txt\n",
      "4  |   ../masc/newspaper_newswire/NYTnewswire9.txt\n",
      "4  |   ../masc/newspaper_newswire/wsj_0120.txt\n",
      "4  |   ../masc/newspaper_newswire/wsj_0158.txt\n",
      "4  |   ../masc/newspaper_newswire/wsj_1640.mrg-NEW.txt\n",
      "4  |   ../masc/newspaper_newswire/wsj_2465.txt\n",
      "4  |   ../masc/philosophy/anth_essay_4.txt\n",
      "4  |   ../masc/philosophy/Ant_Robot.txt\n",
      "4  |   ../masc/philosophy/Applied ethics.txt\n",
      "4  |   ../masc/philosophy/A_defense_of_Michael_Moore.txt\n",
      "4  |   ../masc/philosophy/Bartok.txt\n",
      "4  |   ../masc/philosophy/Black_and_white.txt\n",
      "4  |   ../masc/philosophy/Considerations on Representative Government.txt\n",
      "4  |   ../masc/philosophy/Definitions of art.txt\n",
      "4  |   ../masc/philosophy/External world skepticism.txt\n",
      "4  |   ../masc/philosophy/Free will and free choice.txt\n",
      "4  |   ../masc/philosophy/Homer and Classical Philology.txt\n",
      "4  |   ../masc/philosophy/Homosexuality.txt\n",
      "4  |   ../masc/philosophy/Intentionality.txt\n",
      "4  |   ../masc/philosophy/Introduction to existentialism.txt\n",
      "4  |   ../masc/philosophy/Introduction to the Philosophy of Law.txt\n",
      "4  |   ../masc/philosophy/Just war theory.txt\n",
      "4  |   ../masc/philosophy/Karl Popper and falsificationism.txt\n",
      "4  |   ../masc/philosophy/Madame_White_Snake.txt\n",
      "4  |   ../masc/philosophy/Moral testimony.txt\n",
      "4  |   ../masc/philosophy/Ohio_Steel.txt\n",
      "4  |   ../masc/philosophy/Philosophy and its contrast with science.txt\n",
      "4  |   ../masc/philosophy/Proposed Roads To Freedom.txt\n",
      "4  |   ../masc/philosophy/Thus Spake Zarathustra.txt\n",
      "4  |   ../masc/political_and_economy/chapter-10.txt\n",
      "4  |   ../masc/political_and_economy/Env_Prot_Agency-nov1.txt\n",
      "4  |   ../masc/political_and_economy/fcic_final_report_conclusions.txt\n",
      "4  |   ../masc/political_and_economy/Postal_Rate_Comm-ReportToCongress2002WEB.txt\n",
      "4  |   ../masc/political_and_economy/Principles Of Political Economy.txt\n",
      "4  |   ../masc/political_and_economy/Protocol_Regarding_Access.txt\n",
      "4  |   ../masc/technologies-engineering/1468-6708-3-1.txt\n",
      "4  |   ../masc/technologies-engineering/1468-6708-3-3.txt\n",
      "4  |   ../masc/technologies-engineering/1471-2091-2-9.txt\n",
      "4  |   ../masc/technologies-engineering/1471-213X-1-1.txt\n",
      "4  |   ../masc/technologies-engineering/1471-230X-2-21.txt\n",
      "4  |   ../masc/technologies-engineering/Ancient Egyptian and Greek Looms.txt\n",
      "4  |   ../masc/technologies-engineering/Artificial Light.txt\n",
      "4  |   ../masc/technologies-engineering/concrete_construction.txt\n",
      "4  |   ../masc/technologies-engineering/Cyclopedia of Telephony and Telegraphy.txt\n",
      "4  |   ../masc/technologies-engineering/Delco Manuals.txt\n",
      "4  |   ../masc/technologies-engineering/Development of the Phonograph IBM_1401_programming_systems.txt\n",
      "4  |   ../masc/technologies-engineering/Development of the Phonograph.txt\n",
      "4  |   ../masc/technologies-engineering/diggers_in_the_earth.txt\n",
      "4  |   ../masc/technologies-engineering/how_it_works.txt\n",
      "4  |   ../masc/technologies-engineering/journal.pbio.0020001.txt\n",
      "4  |   ../masc/technologies-engineering/Letters of a Radio-Engineer to His Son,.txt\n",
      "4  |   ../masc/technologies-engineering/makers_of_many_things.txt\n",
      "4  |   ../masc/technologies-engineering/mechanical_properties_of_wood.txt\n",
      "4  |   ../masc/technologies-engineering/Nitro-Explosive.txt\n",
      "4  |   ../masc/technologies-engineering/opportunities_in_ingineering.txt\n",
      "4  |   ../masc/technologies-engineering/origin_of_wlockwork.txt\n",
      "4  |   ../masc/technologies-engineering/pmed.0010029.txt\n",
      "4  |   ../masc/technologies-engineering/Radio Shack TRS-80 Expansion Interface.txt\n",
      "4  |   ../masc/technologies-engineering/rr166.txt\n",
      "4  |   ../masc/technologies-engineering/Soap-Making Manual.txt\n",
      "4  |   ../masc/technologies-engineering/Textiles.txt\n",
      "4  |   ../masc/technologies-engineering/The Art of Making Whiskey.txt\n",
      "4  |   ../masc/technologies-engineering/The Art of Perfumery.txt\n",
      "4  |   ../masc/technologies-engineering/The Earliest Electromagnetic Instruments.txt\n",
      "4  |   ../masc/technologies-engineering/The Early History of the Airplane.txt\n",
      "4  |   ../masc/technologies-engineering/The First Airplane Diesel Engine.txt\n",
      "4  |   ../masc/technologies-engineering/The Introduction of Self-Registering.txt\n",
      "4  |   ../masc/technologies-engineering/The Methods of Glass Blowing.txt\n",
      "4  |   ../masc/technologies-engineering/The Telephone.txt\n",
      "4  |   ../masc/technologies-engineering/the_romance_of_rubber.txt\n",
      "4  |   ../masc/travel-guides/HistoryGreek.txt\n",
      "4  |   ../masc/travel-guides/HistoryJerusalem.txt\n",
      "4  |   ../masc/travel-guides/HistoryLasVegas.txt\n",
      "4  |   ../masc/travel-guides/IntroDublin.txt\n",
      "4  |   ../masc/travel-guides/IntroHongKong.txt\n",
      "4  |   ../masc/travel-guides/WhatToHongKong.txt\n",
      "4  |   ../masc/travel-guides/WhereToHongKong.txt\n",
      "4  |   ../masc/twitter/tweets1.txt\n",
      "4  |   ../masc/twitter/tweets2.txt\n",
      "4  |   ../masc/z_email/.DS_Store\n",
      "4  |   ../masc/z_email/12176.txt\n",
      "4  |   ../masc/z_email/175841.txt\n",
      "4  |   ../masc/z_email/lists-003-2137010.txt\n",
      "4  |   ../masc/z_email/lists-003-2205935.txt\n",
      "4  |   ../masc/z_email/lists-046-11493928.txt\n",
      "4  |   ../masc/z_email/lists-046-12122969.txt\n"
     ]
    }
   ],
   "source": [
    "root_masc = u\"../masc/\"\n",
    "k = 0\n",
    "limit = 4\n",
    "for f in izi.getFileList(root_masc):\n",
    "    sub_root = f+'/'\n",
    "    for ff in izi.getFileList(sub_root):\n",
    "        print str(k) + '  |   ' +  str(ff)\n",
    "        if k < limit:\n",
    "            insertDoc(ff, root = sub_root, prefix = f[len(root_masc):])\n",
    "            k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:1: DeprecationWarning: insert is deprecated. Use insert_one or insert_many instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectId('56643f5a9f5c8d024c0f31b4')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.graph.insert(  getGraph() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scripts import izi\n",
    "reload(izi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fails = []\n",
    "i = 0\n",
    "maxx = 5\n",
    "for f in filelist:\n",
    "    if True: #i < maxx:\n",
    "        try:\n",
    "            print f\n",
    "            insertDoc(f)\n",
    "        except:\n",
    "            fails.append(f)\n",
    "            print \"#\"\n",
    "\n",
    "        i += 1\n",
    "    \n",
    "print\n",
    "print\n",
    "print \"%s fails\" %len(fails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in fails:\n",
    "    print f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cursor = db.documents.find_one()\n",
    "for document in cursor:\n",
    "    print document\n",
    "    \n",
    "    \n",
    "x = cursor[\"_id\"]\n",
    "\n",
    "db.documents.find_one({ \"_id\": x})[\"full_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.similarities.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.translators.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reset collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.documents.drop()\n",
    "db.similarities.drop()\n",
    "db.graph.drop()\n",
    "db.translators.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
